{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-15T19:00:14.873213200Z",
     "start_time": "2023-09-15T19:00:14.853429100Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\nunez\\Facultad\\Factor Data\\Proyecto NLP canciones\\Datasets Scrapeados\\Folklore.csv\")\n",
    "df.dropna(subset=\"Lyrics\",inplace=True)\n",
    "def clean(text):\n",
    "    cleaned_text = re.sub(r\"^.*?Lyrics\", \"\", text)\n",
    "    cleaned_text = re.sub(r'\\[.*?\\]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\([^)]*\\)', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\n', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'Embed', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'you might also like', '', cleaned_text)\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text\n",
    "df[\"Lyrics\"] = df[\"Lyrics\"].astype(str).apply(clean)\n",
    "df[\"Artist_genres\"] = df[\"Artist_genres\"].replace(\"[]\",np.nan)\n",
    "df.dropna(subset=\"Artist_genres\",inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-15T19:00:19.573037500Z",
     "start_time": "2023-09-15T19:00:15.135520600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0       despierta ya mujer asi yo puedo ver la mirada ...\n4       cuando salí de santiago todo el camino lloré l...\n9       dejé mi tierra cantora por conocer otros pagos...\n12      en pampa de los huanacos yo vine dejando una f...\n13      las nostalgias del ayer que traigo en mi canto...\n                              ...                        \n4575    formula denuncia  ministerio público de la nac...\n4581    so who do you no tonigh lazy and gentleman the...\n4583     dicen que el mundo es redondo pero tiene cuat...\n4587    formula denuncia  ministerio público de la nac...\n4589    formula denuncia  ministerio público de la nac...\nName: Lyrics, Length: 1781, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Lyrics\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-15T19:00:19.613051Z",
     "start_time": "2023-09-15T19:00:19.573037500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7545, -0.6453,  1.1431,  ..., -0.0022,  0.4830, -0.6728],\n",
      "        [ 0.5292, -0.6151,  0.3465,  ..., -0.8031, -0.7017, -0.8839],\n",
      "        [-0.0781, -1.1888,  0.8119,  ..., -0.7079, -0.3577, -1.6543],\n",
      "        ...,\n",
      "        [-0.2149, -0.0541, -0.5856,  ..., -0.2377, -0.3910, -1.2556],\n",
      "        [-0.4785, -0.6545, -0.4262,  ...,  0.3892,  0.2259, -0.9087],\n",
      "        [ 0.4094, -0.7337,  0.3785,  ...,  0.2436,  0.4474, -0.8795]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "sentence = df[\"Lyrics\"].iloc[10]\n",
    "\n",
    "\n",
    "tokens = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "\n",
    "\n",
    "token_embeddings = outputs.last_hidden_state\n",
    "\n",
    "\n",
    "embedding_for_first_token = token_embeddings[0]\n",
    "\n",
    "\n",
    "all_token_embeddings = token_embeddings[0]\n",
    "print(all_token_embeddings)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-15T19:00:35.837970700Z",
     "start_time": "2023-09-15T19:00:29.122997600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_name = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for doc in df[\"Lyrics\"]:\n",
    "\n",
    "\n",
    "    tokens = tokenizer(doc, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "\n",
    "    sentence_embeddings = torch.mean(embeddings, dim=1)\n",
    "\n",
    "    all_embeddings.append(sentence_embeddings)\n",
    "\n",
    "\n",
    "final_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-15T19:01:00.123270800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
